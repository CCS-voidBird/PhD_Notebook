Current work:

1. HPC environment transferred into Tensorflow 2.9;
2. MultiLevel Attention development
   1. Main feature 1: added a matrix of attention weights (SNPxSNP int) after softmax(QK^T) to measure weather the dependency is neccessury
   2.  Use 1x1 conv1D and Global average pooling instead of flatten and fully connect layer to generate outputs
   3. The prediction section was changed into a double-portal section:
      1.  A linear one-layer MLP section to predict linear component 
      2.  A non-linear MLP section to predict non-linear component 
3. make 1000 SNP by PIP



Identification of regulatory variation in dairy cattle with RNA sequence data, Author: A.J. Chamberlain

Analysis pipelines:

1. Sample Collection: Mammary gland tissue samples were collected from 20 Holstein-Friesian dairy cows.
2. RNA Isolation: Total RNA was extracted from the tissue samples using a commercial RNA isolation kit.
3. RNA Sequencing: The extracted RNA was subjected to RNA sequencing using Illumina HiSeq 2000 platform to generate the transcriptome data.
4. Pre-processing of RNA-Seq data: The raw sequencing data was pre-processed to remove low-quality reads, adapters, and contaminants using quality control software such as FastQC.
5. Alignment: The pre-processed reads were aligned to the bovine reference genome (UMD3.1.1) using a splice-aware aligner such as STAR.
6. Gene Expression Quantification: The aligned reads were counted and gene expression levels were quantified using software such as HTSeq or FeatureCounts.
7. Quality Control: The quality of the RNA-Seq data was assessed by performing a series of quality control checks such as PCA plots, correlation analysis, and hierarchical clustering.
8. Differential Expression Analysis: The gene expression data was analyzed to identify differentially expressed genes (DEGs) using statistical analysis tools such as edgeR or DESeq2.
9. Functional Annotation: The identified DEGs were subjected to functional annotation analysis to identify enriched gene ontology (GO) terms, biological pathways, and molecular functions.
10. Validation: The results of the RNA sequencing analysis were validated by performing qRT-PCR on a subset of the genes.

```powershell
$composer = "D:\PhD_Notebook\Code\ML_composer\"

$geno = "H:\ML_archive\Data\sugarcane_disease\sugarcane_disease"
$pheno = "H:\ML_archive\Data\sugarcane_disease\sugarcane_disease.phen"
$index = "H:\ML_archive\Data\sugarcane_disease\sugarcane_disease.index"
$target = "H:\ML_archive\test_model" 

##If using subset 
$geno = "H:\ML_archive\Data\sugarcane_disease\subset\disease_subset"
$pheno = "H:\ML_archive\Data\sugarcane_disease\subset\disease_subset.phen"
$index = "H:\ML_archive\Data\sugarcane_disease\subset\disease_subset.index"
$target = "H:\ML_archive\test_model" 

##Bash code
composer="D:\PhD_Notebook\Code\ML_composer\"

geno ="H:\ML_archive\Data\sugarcane_disease\sugarcane_disease"
pheno="H:\ML_archive\Data\sugarcane_disease\sugarcane_disease.phen"
index="H:\ML_archive\Data\sugarcane_disease\sugarcane_disease.index"
target="H:\ML_archive\test_model" 

##If using subset 
geno="H:\ML_archive\Data\sugarcane_disease\subset\disease_subset"
pheno="H:\ML_archive\Data\sugarcane_disease\subset\disease_subset.phen"
index="H:\ML_archive\Data\sugarcane_disease\subset\disease_subset.index"
anno="H:\ML_archive\Data\sugarcane_disease\subset\disease_subset.anno"
target="H:\ML_archive\test_model" 

python $composer/GS_composer.py --ped $geno --pheno $pheno --mpheno 1 --index $index --trait smut --width 256 --depth 0 --model "LNN" -o $target --quiet 1 --plot --epoch 5 --round 1 --locallyConnect 8 --embedding 8 --batch 8

python $composer/GS_composer.py --ped $geno --pheno $pheno --mpheno 1 --index $index --trait smut --width 256 --depth 0 --model "MultiLevelNN" -o $target --quiet 1 --plot --epoch 5 --round 1 --locallyConnect 8 --embedding 8 --batch 8


```

```bash
##Bash code
composer="D:/PhD_Notebook/Code/ML_composer/"

geno="H:/ML_archive/Data/sugarcane_disease/sugarcane_disease"
pheno="H:/ML_archive/Data/sugarcane_disease/sugarcane_disease.phen"
index="H:/ML_archive/Data/sugarcane_disease/sugarcane_disease.index"
anno="H:/ML_archive/Data/sugarcane_disease/sugarcane_disease.anno"
target="H:/ML_archive/test_model" 

##If using subset 
geno="H:/ML_archive/Data/sugarcane_disease/subset/disease_subset"
pheno="H:/ML_archive/Data/sugarcane_disease/subset/disease_subset.phen"
index="H:/ML_archive/Data/sugarcane_disease/subset/disease_subset.index"
anno="H:/ML_archive/Data/sugarcane_disease/subset/disease_subset.anno"
target="H:/ML_archive/test_model" 

python $composer/GS_composer.py --ped $geno --pheno $pheno --mpheno 1 --index $index --trait smut --width 256 --depth 0 --model "LNN" -o $target --quiet 1 --plot --epoch 5 --round 1 --locallyConnect 8 --embedding 8 --batch 8

python $composer/GS_composer.py --ped $geno --pheno $pheno --mpheno 1 --index $index --trait smut --width 256 --depth 1 --model "MultiLevel Attention" -o $target --quiet 1 --plot --epoch 5 --round 1 --locallyConnect 8 --embedding 8 --batch 8 --num-heads 1 --locallyBlock 10

pheno="H:/ML_archive/Data/sugarcane_disease/sugarcane_disease.phen"
index="H:/ML_archive/Data/sugarcane_disease/sugarcane_disease.index"
epoch=30
header="\tTrait\tTrainSet\tValidSet\tModel\tTest_Accuracy\tValid_Accuracy\t${loss}\tRuntime"
#trait="pachy"
loss="mse"

composer="D:/PhD_Notebook/Code/ML_composer/"
for AB in 1 2
do
echo $AB
for idx in {1..5}
do
act="leaky_relu"
trait="smut"
geno="H:/ML_archive/Data/sugarcane_disease/sugarcane_disease_1000_v${idx}_${trait}"
target="H:/ML_archive/PIP_attention/MultiLevel/v${idx}_${AB}AB_noEpi_1000SNP/"
python $composer/GS_composer.py --ped $geno --pheno $pheno --mpheno 1 --index $index --trait $trait --width 256 --depth 1 --model "MultiLevel Attention" -o $target --quiet 1 --plot --epoch $epoch --round 1 --locallyConnect 16 --embedding 16 --AttentionBlock $AB --activation $act --batch 256 --num-heads 1 --locallyBlock 1 --vindex $idx --lr 0.001 --loss $loss

target="H:/ML_archive/PIP_attention/MultiLevel/v${idx}_${AB}AB_Epi_1000SNP/"
python $composer/GS_composer.py --ped $geno --pheno $pheno --mpheno 1 --index $index --trait $trait --width 256 --depth 1 --model "MultiLevel Attention" -o $target --quiet 1 --plot --epoch $epoch --round 1 --locallyConnect 16 --embedding 16 --AttentionBlock $AB --activation $act --batch 256 --num-heads 1 --locallyBlock 1 --epistatic --vindex $idx --lr 0.001 --loss $loss

trait="pachy"
target="H:/ML_archive/PIP_attention/MultiLevel/v${idx}_${AB}AB_noEpi_1000SNP/"
echo $trait
python $composer/GS_composer.py --ped $geno --pheno $pheno --mpheno 2 --index $index --trait $trait --width 256 --depth 1 --model "MultiLevel Attention" -o $target --quiet 1 --plot --epoch $epoch --round 1 --locallyConnect 16 --embedding 16 --AttentionBlock $AB --activation $act --batch 256 --num-heads 1 --locallyBlock 1 --vindex $idx --lr 0.001 --loss $loss

target="H:/ML_archive/PIP_attention/MultiLevel/v${idx}_${AB}AB_Epi_1000SNP/"
python $composer/GS_composer.py --ped $geno --pheno $pheno --mpheno 2 --index $index --trait $trait --width 256 --depth 1 --model "MultiLevel Attention" -o $target --quiet 1 --plot --epoch $epoch --round 1 --locallyConnect 16 --embedding 16 --AttentionBlock $AB --activation $act --batch 256 --num-heads 1 --locallyBlock 1 --epistatic --vindex $idx --lr 0.001 --loss $loss

done
done

header="\tTrait\tTrainSet\tValidSet\tModel\tTest_Accuracy\tValid_Accuracy\t${loss}\tRuntime"
echo $loss
for epi in Epi noEpi
do 
echo "epi is ${epi}"
for trait in smut pachy
do
path="H:/ML_archive/PIP_attention/MultiLevel/2AB_${epi}_1000SNP/"
mkdir -p $path
mkdir -p $path/${trait}_MultiLevelAttention_${trait}/
echo -e $header > $path/MultiLevelAttention_train_record_$trait.csv
for idx in {1..5}
do
echo $idx
cat H:/ML_archive/PIP_attention/MultiLevel/v${idx}_2AB_${epi}_1000SNP/MultiLevelAttention_train_record_${trait}.csv | grep -v "Trait" >> $path/MultiLevelAttention_train_record_${trait}.csv
cp H:/ML_archive/PIP_attention/MultiLevel/v${idx}_2AB_${epi}_1000SNP/model_summary.txt $path/
cp  H:/ML_archive/PIP_attention/MultiLevel/v${idx}_2AB_${epi}_1000SNP/${trait}_MultiLevelAttention_${trait}/* $path/${trait}_MultiLevelAttention_${trait}/
#echo -e $header
done
done
done

```

Experimental plans:

1. One attention block
2. double attention with residual connection
3. One attention block with epi matrix
4. all the above models use LNN and 1x1 conv1D as regression block (with dominance estimate block)
5. LD block between 10 - 100; 1000 top SNP extracted by bayesR
6. mse and mae as loss function

```python


### Code for previous group LD connected layer
@tf.function
def tf_zip(a,b):
    return zip(a,b)
    
class GroupedLocallyConnectedLayer(layers.Layer):
    def __init__(self, channels,reference, **kwargs):
        super(GroupedLocallyConnectedLayer, self).__init__(**kwargs)
        self.num_groups = len(reference)
        self.channels = channels
        self.group_reference = reference ## reference format: [[0,1,2],[3,4,5],[6,7,8]...]

    def build(self, input_shape):
        input_dim = input_shape[-1]
        #sum_channels = sum(self.group_sizes)
        self.group_sizes = [len(x) for x in self.group_reference]  #[input_dim // self.num_groups] * self.num_groups
        #remainder = input_dim % self.num_groups
        #for i in range(remainder):
        #    self.group_sizes[i] += 1
        self.kernels = [self.add_weight(shape=(self.channels,self.group_sizes[i],input_dim), 
                                        initializer='glorot_uniform', 
                                        name='kernel_{}'.format(i)) for i in range(self.num_groups)]
        
    @tf.function
    def create_ld_pairs(self,inputs):
        groups = zip([tf.gather(inputs,pos,axis=1) for pos in self.group_reference],self.kernels)
        outputs = [tf.matmul(selected_input, kernel,transpose_b=True) for selected_input,kernel in pairs]
        return outputs
        
    @tf.function
    def call(self, inputs):
        groups = []
        """
        #for i,pos in enumerate(self.group_reference):
        for i,pos in tf.data.Dataset.from_tensor_slices((indices, self.group_reference)):
            pos = pos.numpy().tolist()
            selected_input = tf.gather(inputs, pos, axis=1)
            group_cal = tf.matmul(selected_input, self.kernels[i],transpose_b=True)
            groups.append(group_cal)
        """
        
        outputs = self.create_ld_pairs(inputs)
        output = tf.concat(outputs, axis=1)
        return output

    def compute_output_shape(self, input_shape):
        output_features = len(self.group_sizes)
        return (input_shape[0], output_features + 1, self.channels)
```

![](C:\Users\70651\AppData\Roaming\Typora\typora-user-images\image-20230530144447692.png)

```bash
##get bayesian scores###
path="/scratch/user/s4563146/sugarcane_disease/gctb"
for trait in smut pachy
do
echo $trait
for model in bayesC bayesR
do
echo $model
for i in {1..5}
do 
echo $i; 
cat ${trait}_${model}_1000/${trait}_v${i}.snpRes | awk -F"  +" '{print $3,$6,$9}' > ${trait}_${model}_1000/${trait}_v${i}.snpEff; 
~/plink --bfile ../data/Bayes1000/ForPlink/sugarcane_disease_1000_v${i}_${trait} --score ${trait}_${model}_1000/${trait}_v${i}.snpEff header sum --out ${trait}_${model}_1000/${trait}_v${i}.score; done
done
done


for loss in mse mae
do
header="\tTrait\tTrainSet\tValidSet\tModel\tTest_Accuracy\tValid_Accuracy\t${loss}\tRuntime" 
echo $loss
for lb in 1 5 10
do 
echo "LB is ${lb}"
for trait in smut pachy
do
echo $trait
mkdir -p MultiLevel_Attention_1Head16eb16LC${lb}LB_1000BayesRsSNP_${loss}_pcaIndex
echo -e $header > MultiLevel_Attention_1Head16eb16LC${lb}LB_1000BayesRsSNP_${loss}_pcaIndex/MultiLevelAttention_train_record_${trait}.csv
cat MultiLevel_Attention_1Head16eb16LC${lb}LB_1000BayesRsSNP_v*_${loss}_pcaIndex/MultiLevelAttention_train_record_${trait}.csv | grep -v "Trait" >> MultiLevel_Attention_1Head16eb16LC${lb}LB_1000BayesRsSNP_${loss}_pcaIndex/MultiLevelAttention_train_record_${trait}.csv
echo -e $header
cat MultiLevel_Attention_1Head16eb16LC${lb}LB_1000BayesRsSNP_v*_${loss}_pcaIndex/MultiLevelAttention_train_record_${trait}.csv | grep -v "Trait"
done
done
done

```

