Fundamental Deep neural network



basic strategy:

+ input layer (0th layer)
+ hidden layer

Activation functions

sigmoid:

$Equation:$	$f(x)=\frac{1}{1+e^{-x}}$

$Derivative:$	$\frac{d(y)}{d(x)}=f(x)(1-f(x))$



![Activation Functions and their Derivatives](https://editor.analyticsvidhya.com/uploads/94131Screenshot%20(43).png)

