{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "619d63d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from CustomLayers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98f598e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_path = \"C:/Users/uqcche32/OneDrive - The University of Queensland/PhD/HPC_Results/Sugarcane_disease/ML/Attention_Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31d3de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306b8b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    F:\\PhD_Notebook\\Code\\ML_composer\\CustomLayers.py:227 call  *\n        query = tf.einsum('bsd,dd->bsd',X,self.wq)\n    F:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper  **\n        return target(*args, **kwargs)\n    F:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\ops\\special_math_ops.py:751 einsum\n        return _einsum_v2(equation, *inputs, **kwargs)\n    F:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\ops\\special_math_ops.py:1180 _einsum_v2\n        return gen_linalg_ops.einsum(inputs, resolved_equation)\n    F:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_linalg_ops.py:1090 einsum\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    F:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    F:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:599 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    F:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3557 _create_op_internal\n        ret = Operation(\n    F:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2041 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    F:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Shape must be rank 3 but is rank 2\n    \t for 0th input and equation: bsd,dd->bsd for '{{node multi_head_qkv__block_attention/einsum/Einsum}} = Einsum[N=2, T=DT_FLOAT, equation=\"bsd,dd->bsd\"](multi_head_qkv__block_attention/strided_slice, multi_head_qkv__block_attention/einsum/Einsum/ReadVariableOp)' with input shapes: [2608,12], [12,12].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmut_MultiHeadAttentionLNN_1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m full_path \u001b[38;5;241m=\u001b[39m Model_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_folder\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMultiHead_QKV_BlockAttention\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mMultiHead_QKV_BlockAttention\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py:206\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    204\u001b[0m       filepath \u001b[38;5;241m=\u001b[39m path_to_string(filepath)\n\u001b[0;32m    205\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 206\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaved_model_load\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnable to load model. Filepath is not an hdf5 file (or h5py is not \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavailable) or SavedModel.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py:155\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, compile, options)\u001b[0m\n\u001b[0;32m    152\u001b[0m loaded \u001b[38;5;241m=\u001b[39m tf_load\u001b[38;5;241m.\u001b[39mload_partial(path, nodes_to_load, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# Finalize the loaded layers and remove the extra tracked dependencies.\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m \u001b[43mkeras_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinalize_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m keras_loader\u001b[38;5;241m.\u001b[39mdel_tracking()\n\u001b[0;32m    158\u001b[0m model \u001b[38;5;241m=\u001b[39m loaded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py:626\u001b[0m, in \u001b[0;36mKerasObjectLoader.finalize_objects\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    623\u001b[0m _finalize_config_layers(layers_revived_from_config)\n\u001b[0;32m    625\u001b[0m \u001b[38;5;66;03m# Initialize graph networks, now that layer dependencies have been resolved.\u001b[39;00m\n\u001b[1;32m--> 626\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reconstruct_all_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py:645\u001b[0m, in \u001b[0;36mKerasObjectLoader._reconstruct_all_models\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m   all_initialized_models\u001b[38;5;241m.\u001b[39madd(model_id)\n\u001b[0;32m    644\u001b[0m   model, layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_layer_dependencies[model_id]\n\u001b[1;32m--> 645\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reconstruct_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    646\u001b[0m   _finalize_config_layers([model])\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_initialized_models \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_layer_dependencies\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[0;32m    649\u001b[0m   \u001b[38;5;66;03m# This should not happen.\u001b[39;00m\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\load.py:691\u001b[0m, in \u001b[0;36mKerasObjectLoader._reconstruct_model\u001b[1;34m(self, model_id, model, layers)\u001b[0m\n\u001b[0;32m    688\u001b[0m       model\u001b[38;5;241m.\u001b[39mbuild(input_shapes)\n\u001b[0;32m    689\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Reconstruct functional model\u001b[39;00m\n\u001b[0;32m    690\u001b[0m   (inputs, outputs,\n\u001b[1;32m--> 691\u001b[0m    created_layers) \u001b[38;5;241m=\u001b[39m \u001b[43mfunctional_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconstruct_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m       \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreated_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    693\u001b[0m   model\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(inputs, outputs, name\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    694\u001b[0m   functional_lib\u001b[38;5;241m.\u001b[39mconnect_ancillary_layers(model, created_layers)\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:1289\u001b[0m, in \u001b[0;36mreconstruct_from_config\u001b[1;34m(config, custom_objects, created_layers)\u001b[0m\n\u001b[0;32m   1287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m unprocessed_nodes:\n\u001b[0;32m   1288\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m node_data \u001b[38;5;129;01min\u001b[39;00m unprocessed_nodes\u001b[38;5;241m.\u001b[39mpop(layer):\n\u001b[1;32m-> 1289\u001b[0m         \u001b[43mprocess_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1291\u001b[0m input_tensors \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1292\u001b[0m output_tensors \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:1237\u001b[0m, in \u001b[0;36mreconstruct_from_config.<locals>.process_node\u001b[1;34m(layer, node_data)\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m layer\u001b[38;5;241m.\u001b[39m_preserve_input_structure_in_config:\n\u001b[0;32m   1235\u001b[0m   input_tensors \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1236\u001b[0m       base_layer_utils\u001b[38;5;241m.\u001b[39munnest_if_single_tensor(input_tensors))\n\u001b[1;32m-> 1237\u001b[0m output_tensors \u001b[38;5;241m=\u001b[39m layer(input_tensors, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;66;03m# Update node index map.\u001b[39;00m\n\u001b[0;32m   1240\u001b[0m output_index \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mflatten(output_tensors)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_keras_history\u001b[38;5;241m.\u001b[39mnode_index\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:969\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[38;5;66;03m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;66;03m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[0;32m    965\u001b[0m \u001b[38;5;66;03m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;66;03m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[38;5;66;03m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _in_functional_construction_mode(\u001b[38;5;28mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[1;32m--> 969\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_functional_construction_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[0;32m    973\u001b[0m call_context \u001b[38;5;241m=\u001b[39m base_layer_utils\u001b[38;5;241m.\u001b[39mcall_context()\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1107\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     training_arg_passed_by_framework \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m call_context\u001b[38;5;241m.\u001b[39menter(\n\u001b[0;32m   1105\u001b[0m     layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, inputs\u001b[38;5;241m=\u001b[39minputs, build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39mtraining_value):\n\u001b[0;32m   1106\u001b[0m   \u001b[38;5;66;03m# Check input assumptions set after layer building, e.g. input shape.\u001b[39;00m\n\u001b[1;32m-> 1107\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_keras_tensor_symbolic_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1110\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA layer\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms `call` method should return a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1112\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensor or a list of Tensors, not None \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1113\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(layer: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:840\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    838\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mmap_structure(keras_tensor\u001b[38;5;241m.\u001b[39mKerasTensor, output_signature)\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 840\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_output_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:880\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_build(inputs)\n\u001b[0;32m    879\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[1;32m--> 880\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_mask_metadata(inputs, outputs, input_masks,\n\u001b[0;32m    884\u001b[0m                         build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:695\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    694\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m    696\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    F:\\PhD_Notebook\\Code\\ML_composer\\CustomLayers.py:227 call  *\n        query = tf.einsum('bsd,dd->bsd',X,self.wq)\n    F:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper  **\n        return target(*args, **kwargs)\n    F:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\ops\\special_math_ops.py:751 einsum\n        return _einsum_v2(equation, *inputs, **kwargs)\n    F:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\ops\\special_math_ops.py:1180 _einsum_v2\n        return gen_linalg_ops.einsum(inputs, resolved_equation)\n    F:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_linalg_ops.py:1090 einsum\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    F:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    F:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:599 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    F:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3557 _create_op_internal\n        ret = Operation(\n    F:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2041 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    F:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Shape must be rank 3 but is rank 2\n    \t for 0th input and equation: bsd,dd->bsd for '{{node multi_head_qkv__block_attention/einsum/Einsum}} = Einsum[N=2, T=DT_FLOAT, equation=\"bsd,dd->bsd\"](multi_head_qkv__block_attention/strided_slice, multi_head_qkv__block_attention/einsum/Einsum/ReadVariableOp)' with input shapes: [2608,12], [12,12].\n"
     ]
    }
   ],
   "source": [
    "model_folder = \"smut_MultiHeadAttentionLNN_1\"\n",
    "full_path = Model_path + \"/\" + model_folder\n",
    "model = keras.models.load_model(full_path,custom_objects={\"MultiHead_QKV_BlockAttention\": MultiHead_QKV_BlockAttention})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57d9a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360fd93b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
