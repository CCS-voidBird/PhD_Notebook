Fundamental Deep neural network



basic strategy:

+ input layer (0th layer)
+ hidden layer

Activation functions

sigmoid:

$Equation:$	$f(x)=\frac{1}{1+e^{-x}}$

$Derivative:$	$\frac{d(y)}{d(x)}=f(x)(1-f(x))$



![Activation Functions and their Derivatives](https://editor.analyticsvidhya.com/uploads/94131Screenshot%20(43).png)



Multilayer perceptron study; current problems:

+ Backward propagation
+ loss function
+ core theory in math
+ more hyper-parameters
+ run code with numpy module 





**Partial derivative**

+ $f^{'}_x = \frac{\partial{f}}{\part{x}}$
+ $\delta$



Cross-Entropy Function:

![image-20210806213722473](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20210806213722473.png)





##Multi-Depth neural network## 





