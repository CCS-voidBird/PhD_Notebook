{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\ANACONDA\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "D:\\ANACONDA\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\learning resource\\PhD\\PHD_Notebook\\Code\\ML_composer\\ClassModel.py:31: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.run_functions_eagerly` instead of the experimental version.\n"
     ]
    }
   ],
   "source": [
    "from CustomLayers import *\n",
    "from GS_composer import *\n",
    "from Functions import *\n",
    "from ClassModel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profile = \"E:/learning resource/\"\n",
    "Model_path = user_profile+\"OneDrive - The University of Queensland/PhD/HPC_Results/Sugarcane_disease/ML/1Head_RealForm32_32LocalB\"\n",
    "#Model_path = \"E:/learning resource/OneDrive - The University of Queensland/PhD/HPC_Results/Sugarcane_disease/ML/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([None, 2608, 32])]\n",
      "[TensorShape([None, 2608, 32]), TensorShape([None, 2608, 32])]\n"
     ]
    }
   ],
   "source": [
    "model_folder = \"pachy_MultiHeadAttentionLNN_1\"\n",
    "#model_folder = \"test_model\"\n",
    "full_path = Model_path + \"/\" + model_folder\n",
    "model = keras.models.load_model(full_path,custom_objects={\"MultiHead_QKV_BlockAttention\": MultiHead_QKV_BlockAttention,\n",
    "                                                         \"SNPBlockLayer\":SNPBlockLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "#model = keras.Model(inputs=input1, outputs=QV_output)\n",
    "model.compile(optimizer=\"RMSprop\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.7426164]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = np.ones((1, 26086, 1))\n",
    "model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_layer_model = tf.keras.Model(inputs=model.input,\n",
    "                                         outputs=model.get_layer('add_3').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_output = intermediate_layer_model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = intermediate_output[0]\n",
    "attention = K.expand_dims(attention,axis=1)\n",
    "print(attention.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LNN_weight = model.layers[2].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LNN_weight[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNP_attention = tf.multiply(attention,LNN_weight[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNP_attention = tf.reshape(SNP_attention,(26080,1,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_SNP_attention = SNP_attention #tf.reduce_mean(SNP_attention,axis=2)\n",
    "mean_SNP_attention.shape\n",
    "mean_SNP_attention = np.array(tf.reshape(mean_SNP_attention,(26080*32,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_SNP_attention.shape)\n",
    "plt.scatter(x=np.tile(np.arange(0,26080),32),y=abs((mean_SNP_attention)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_SNP_attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_attention_score_by_trait(filename,trait,val):\n",
    "    model = keras.models.load_model(filename,custom_objects={\"MultiHead_QKV_BlockAttention\": MultiHead_QKV_BlockAttention,\n",
    "                                                         \"SNPBlockLayer\":SNPBlockLayer})\n",
    "    model.summary()\n",
    "    #model = keras.Model(inputs=input1, outputs=QV_output)\n",
    "    model.compile(optimizer=\"RMSprop\", loss=\"mean_squared_error\")\n",
    "    data = np.ones((1, 26086, 1))\n",
    "    intermediate_layer_model = tf.keras.Model(inputs=model.input,\n",
    "                                         outputs=model.get_layer('add_3').output)\n",
    "    intermediate_output = intermediate_layer_model.predict(data)\n",
    "    attention = intermediate_output[0]\n",
    "    attention = K.expand_dims(attention,axis=1)\n",
    "    print(attention.shape)\n",
    "    \n",
    "    LNN_weight = model.layers[2].get_weights()\n",
    "    SNP_attention = tf.multiply(attention,LNN_weight[0])\n",
    "    SNP_attention = np.array(tf.reshape(SNP_attention,(32,26080)))\n",
    "    SNP_attention = pd.DataFrame(SNP_attention,columns=list(range(1,SNP_attention.shape[1]+1)))\n",
    "    SNP_attention.shape\n",
    "    SNP_attention.insert(0,'Channel',range(1,33))\n",
    "    SNP_attention.insert(0,'Val',val)\n",
    "    SNP_attention.insert(0,\"Trait\",trait)\n",
    "    \n",
    "    SNP_attention = SNP_attention.values.tolist()\n",
    "    #mean_SNP_attention = [trait,val]+list(np.array(tf.reshape(mean_SNP_attention,(26080,))))\n",
    "    #mean_SNP_attention = pd.DataFrame([trait,val]+list(mean_SNP_attention),columns=[trait,val]+list(range(1,length(mean_SNP_attention))))\n",
    "\n",
    "    return SNP_attention\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_LD_attention_score_by_trait(filename,trait,val):\n",
    "    model = keras.models.load_model(filename,custom_objects={\"MultiHead_QKV_BlockAttention\": MultiHead_QKV_BlockAttention,\n",
    "                                                         \"SNPBlockLayer\":SNPBlockLayer})\n",
    "    model.summary()\n",
    "    #model = keras.Model(inputs=input1, outputs=QV_output)\n",
    "    model.compile(optimizer=\"RMSprop\", loss=\"mean_squared_error\")\n",
    "    data = np.ones((1, 26086, 1))\n",
    "    intermediate_layer_model = tf.keras.Model(inputs=model.input,\n",
    "                                         outputs=model.get_layer('multi_head_qkv__block_attention').output)\n",
    "    intermediate_output = intermediate_layer_model.predict(data)\n",
    "    attention = intermediate_output[0]\n",
    "    attention = K.expand_dims(attention,axis=1)\n",
    "    print(attention.shape)\n",
    "    \n",
    "    #LNN_weight = model.layers[2].get_weights()\n",
    "    #SNP_attention = tf.multiply(attention,LNN_weight[0])\n",
    "    LD_attention = np.array(tf.reshape(attention,(32,2608)))\n",
    "    LD_attention = pd.DataFrame(LD_attention,columns=list(range(1,LD_attention.shape[1]+1)))\n",
    "\n",
    "    LD_attention.insert(0,'Channel',range(1,33))\n",
    "    LD_attention.insert(0,'Val',val)\n",
    "    LD_attention.insert(0,\"Trait\",trait)\n",
    "    \n",
    "    LD_attention = LD_attention.values.tolist()\n",
    "    #mean_SNP_attention = [trait,val]+list(np.array(tf.reshape(mean_SNP_attention,(26080,))))\n",
    "    #mean_SNP_attention = pd.DataFrame([trait,val]+list(mean_SNP_attention),columns=[trait,val]+list(range(1,length(mean_SNP_attention))))\n",
    "    model = None\n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    return LD_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([None, 2608, 32])]\n",
      "[TensorShape([None, 2608, 32]), TensorShape([None, 2608, 32])]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_1 (InputLayer)      [(None, 26086, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding1d (ZeroPadding1D)  (None, 26086, 1)     0           input_layer_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d (LocallyCon (None, 2608, 32)     834560      zero_padding1d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2608, 32)     1056        locally_connected1d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_qkv__block_attention ((2608, 32), (2608,  3200        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2608, 32)     0           multi_head_qkv__block_attention[0\n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 2608, 32)     64          add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2608, 32)     1056        layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 2608, 32)     0           dense_1[0][0]                    \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    multiple             0           add_1[0][0]                      \n",
      "                                                                 add_3[0][0]                      \n",
      "                                                                 add_4[0][0]                      \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_qkv__block_attention ((None, 2608, 32), ( 3200        re_lu[0][0]                      \n",
      "                                                                 multi_head_qkv__block_attention[0\n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 2608, 32)     0           multi_head_qkv__block_attention_1\n",
      "                                                                 re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 2608, 32)     64          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2608, 32)     1056        layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 2608, 32)     0           dense_2[0][0]                    \n",
      "                                                                 layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 83456)        0           re_lu[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 83456)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          21364992    dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          65792       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 256)          0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          65792       re_lu[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            257         re_lu[3][0]                      \n",
      "==================================================================================================\n",
      "Total params: 22,341,089\n",
      "Trainable params: 22,341,089\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2608, 1, 32)\n",
      "[TensorShape([None, 2608, 32])]\n",
      "[TensorShape([None, 2608, 32]), TensorShape([None, 2608, 32])]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_1 (InputLayer)      [(None, 26086, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding1d (ZeroPadding1D)  (None, 26086, 1)     0           input_layer_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d (LocallyCon (None, 2608, 32)     834560      zero_padding1d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2608, 32)     1056        locally_connected1d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_qkv__block_attention ((2608, 32), (2608,  3200        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2608, 32)     0           multi_head_qkv__block_attention[0\n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 2608, 32)     64          add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2608, 32)     1056        layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 2608, 32)     0           dense_1[0][0]                    \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    multiple             0           add_1[0][0]                      \n",
      "                                                                 add_3[0][0]                      \n",
      "                                                                 add_4[0][0]                      \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_qkv__block_attention ((None, 2608, 32), ( 3200        re_lu[0][0]                      \n",
      "                                                                 multi_head_qkv__block_attention[0\n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 2608, 32)     0           multi_head_qkv__block_attention_1\n",
      "                                                                 re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 2608, 32)     64          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2608, 32)     1056        layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 2608, 32)     0           dense_2[0][0]                    \n",
      "                                                                 layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 83456)        0           re_lu[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 83456)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          21364992    dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          65792       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 256)          0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          65792       re_lu[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            257         re_lu[3][0]                      \n",
      "==================================================================================================\n",
      "Total params: 22,341,089\n",
      "Trainable params: 22,341,089\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "(2608, 1, 32)\n",
      "[TensorShape([None, 2608, 32])]\n",
      "[TensorShape([None, 2608, 32]), TensorShape([None, 2608, 32])]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_1 (InputLayer)      [(None, 26086, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding1d (ZeroPadding1D)  (None, 26086, 1)     0           input_layer_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d (LocallyCon (None, 2608, 32)     834560      zero_padding1d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2608, 32)     1056        locally_connected1d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_qkv__block_attention ((2608, 32), (2608,  3200        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2608, 32)     0           multi_head_qkv__block_attention[0\n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 2608, 32)     64          add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2608, 32)     1056        layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 2608, 32)     0           dense_1[0][0]                    \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    multiple             0           add_1[0][0]                      \n",
      "                                                                 add_3[0][0]                      \n",
      "                                                                 add_4[0][0]                      \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_qkv__block_attention ((None, 2608, 32), ( 3200        re_lu[0][0]                      \n",
      "                                                                 multi_head_qkv__block_attention[0\n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 2608, 32)     0           multi_head_qkv__block_attention_1\n",
      "                                                                 re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 2608, 32)     64          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2608, 32)     1056        layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 2608, 32)     0           dense_2[0][0]                    \n",
      "                                                                 layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 83456)        0           re_lu[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 83456)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          21364992    dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          65792       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 256)          0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          65792       re_lu[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            257         re_lu[3][0]                      \n",
      "==================================================================================================\n",
      "Total params: 22,341,089\n",
      "Trainable params: 22,341,089\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2608, 1, 32)\n",
      "[TensorShape([None, 2608, 32])]\n",
      "[TensorShape([None, 2608, 32]), TensorShape([None, 2608, 32])]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_1 (InputLayer)      [(None, 26086, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding1d (ZeroPadding1D)  (None, 26086, 1)     0           input_layer_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d (LocallyCon (None, 2608, 32)     834560      zero_padding1d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2608, 32)     1056        locally_connected1d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_qkv__block_attention ((2608, 32), (2608,  3200        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2608, 32)     0           multi_head_qkv__block_attention[0\n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 2608, 32)     64          add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2608, 32)     1056        layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 2608, 32)     0           dense_1[0][0]                    \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    multiple             0           add_1[0][0]                      \n",
      "                                                                 add_3[0][0]                      \n",
      "                                                                 add_4[0][0]                      \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_qkv__block_attention ((None, 2608, 32), ( 3200        re_lu[0][0]                      \n",
      "                                                                 multi_head_qkv__block_attention[0\n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 2608, 32)     0           multi_head_qkv__block_attention_1\n",
      "                                                                 re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 2608, 32)     64          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2608, 32)     1056        layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 2608, 32)     0           dense_2[0][0]                    \n",
      "                                                                 layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 83456)        0           re_lu[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 83456)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          21364992    dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          65792       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 256)          0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          65792       re_lu[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            257         re_lu[3][0]                      \n",
      "==================================================================================================\n",
      "Total params: 22,341,089\n",
      "Trainable params: 22,341,089\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "(2608, 1, 32)\n",
      "[TensorShape([None, 2608, 32])]\n",
      "[TensorShape([None, 2608, 32]), TensorShape([None, 2608, 32])]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_1 (InputLayer)      [(None, 26086, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding1d (ZeroPadding1D)  (None, 26086, 1)     0           input_layer_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d (LocallyCon (None, 2608, 32)     834560      zero_padding1d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2608, 32)     1056        locally_connected1d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_qkv__block_attention ((2608, 32), (2608,  3200        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2608, 32)     0           multi_head_qkv__block_attention[0\n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 2608, 32)     64          add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2608, 32)     1056        layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 2608, 32)     0           dense_1[0][0]                    \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    multiple             0           add_1[0][0]                      \n",
      "                                                                 add_3[0][0]                      \n",
      "                                                                 add_4[0][0]                      \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_qkv__block_attention ((None, 2608, 32), ( 3200        re_lu[0][0]                      \n",
      "                                                                 multi_head_qkv__block_attention[0\n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 2608, 32)     0           multi_head_qkv__block_attention_1\n",
      "                                                                 re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 2608, 32)     64          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2608, 32)     1056        layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 2608, 32)     0           dense_2[0][0]                    \n",
      "                                                                 layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 83456)        0           re_lu[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 83456)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          21364992    dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          65792       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 256)          0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          65792       re_lu[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            257         re_lu[3][0]                      \n",
      "==================================================================================================\n",
      "Total params: 22,341,089\n",
      "Trainable params: 22,341,089\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2608, 1, 32)\n",
      "[TensorShape([None, 2608, 32])]\n",
      "[TensorShape([None, 2608, 32]), TensorShape([None, 2608, 32])]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_1 (InputLayer)      [(None, 26086, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding1d (ZeroPadding1D)  (None, 26086, 1)     0           input_layer_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d (LocallyCon (None, 2608, 32)     834560      zero_padding1d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2608, 32)     1056        locally_connected1d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_qkv__block_attention ((2608, 32), (2608,  3200        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2608, 32)     0           multi_head_qkv__block_attention[0\n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 2608, 32)     64          add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2608, 32)     1056        layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 2608, 32)     0           dense_1[0][0]                    \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    multiple             0           add_1[0][0]                      \n",
      "                                                                 add_3[0][0]                      \n",
      "                                                                 add_4[0][0]                      \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_qkv__block_attention ((None, 2608, 32), ( 3200        re_lu[0][0]                      \n",
      "                                                                 multi_head_qkv__block_attention[0\n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 2608, 32)     0           multi_head_qkv__block_attention_1\n",
      "                                                                 re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 2608, 32)     64          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2608, 32)     1056        layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 2608, 32)     0           dense_2[0][0]                    \n",
      "                                                                 layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 83456)        0           re_lu[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 83456)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          21364992    dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          65792       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 256)          0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          65792       re_lu[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            257         re_lu[3][0]                      \n",
      "==================================================================================================\n",
      "Total params: 22,341,089\n",
      "Trainable params: 22,341,089\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "(2608, 1, 32)\n",
      "[TensorShape([None, 2608, 32])]\n",
      "[TensorShape([None, 2608, 32]), TensorShape([None, 2608, 32])]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_1 (InputLayer)      [(None, 26086, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding1d (ZeroPadding1D)  (None, 26086, 1)     0           input_layer_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d (LocallyCon (None, 2608, 32)     834560      zero_padding1d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2608, 32)     1056        locally_connected1d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_qkv__block_attention ((2608, 32), (2608,  3200        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2608, 32)     0           multi_head_qkv__block_attention[0\n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 2608, 32)     64          add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2608, 32)     1056        layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 2608, 32)     0           dense_1[0][0]                    \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    multiple             0           add_1[0][0]                      \n",
      "                                                                 add_3[0][0]                      \n",
      "                                                                 add_4[0][0]                      \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_qkv__block_attention ((None, 2608, 32), ( 3200        re_lu[0][0]                      \n",
      "                                                                 multi_head_qkv__block_attention[0\n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 2608, 32)     0           multi_head_qkv__block_attention_1\n",
      "                                                                 re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 2608, 32)     64          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2608, 32)     1056        layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 2608, 32)     0           dense_2[0][0]                    \n",
      "                                                                 layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 83456)        0           re_lu[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 83456)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          21364992    dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          65792       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 256)          0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          65792       re_lu[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            257         re_lu[3][0]                      \n",
      "==================================================================================================\n",
      "Total params: 22,341,089\n",
      "Trainable params: 22,341,089\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2608, 1, 32)\n",
      "[TensorShape([None, 2608, 32])]\n",
      "[TensorShape([None, 2608, 32]), TensorShape([None, 2608, 32])]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_1 (InputLayer)      [(None, 26086, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding1d (ZeroPadding1D)  (None, 26086, 1)     0           input_layer_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d (LocallyCon (None, 2608, 32)     834560      zero_padding1d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2608, 32)     1056        locally_connected1d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_qkv__block_attention ((2608, 32), (2608,  3200        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2608, 32)     0           multi_head_qkv__block_attention[0\n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 2608, 32)     64          add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2608, 32)     1056        layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 2608, 32)     0           dense_1[0][0]                    \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    multiple             0           add_1[0][0]                      \n",
      "                                                                 add_3[0][0]                      \n",
      "                                                                 add_4[0][0]                      \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_qkv__block_attention ((None, 2608, 32), ( 3200        re_lu[0][0]                      \n",
      "                                                                 multi_head_qkv__block_attention[0\n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 2608, 32)     0           multi_head_qkv__block_attention_1\n",
      "                                                                 re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 2608, 32)     64          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2608, 32)     1056        layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 2608, 32)     0           dense_2[0][0]                    \n",
      "                                                                 layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 83456)        0           re_lu[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 83456)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          21364992    dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          65792       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 256)          0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          65792       re_lu[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            257         re_lu[3][0]                      \n",
      "==================================================================================================\n",
      "Total params: 22,341,089\n",
      "Trainable params: 22,341,089\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "(2608, 1, 32)\n",
      "[TensorShape([None, 2608, 32])]\n",
      "[TensorShape([None, 2608, 32]), TensorShape([None, 2608, 32])]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_1 (InputLayer)      [(None, 26086, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding1d (ZeroPadding1D)  (None, 26086, 1)     0           input_layer_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d (LocallyCon (None, 2608, 32)     834560      zero_padding1d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2608, 32)     1056        locally_connected1d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_qkv__block_attention ((2608, 32), (2608,  3200        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2608, 32)     0           multi_head_qkv__block_attention[0\n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 2608, 32)     64          add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2608, 32)     1056        layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 2608, 32)     0           dense_1[0][0]                    \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    multiple             0           add_1[0][0]                      \n",
      "                                                                 add_3[0][0]                      \n",
      "                                                                 add_4[0][0]                      \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_qkv__block_attention ((None, 2608, 32), ( 3200        re_lu[0][0]                      \n",
      "                                                                 multi_head_qkv__block_attention[0\n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 2608, 32)     0           multi_head_qkv__block_attention_1\n",
      "                                                                 re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 2608, 32)     64          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2608, 32)     1056        layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 2608, 32)     0           dense_2[0][0]                    \n",
      "                                                                 layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 83456)        0           re_lu[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 83456)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          21364992    dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          65792       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 256)          0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          65792       re_lu[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            257         re_lu[3][0]                      \n",
      "==================================================================================================\n",
      "Total params: 22,341,089\n",
      "Trainable params: 22,341,089\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2608, 1, 32)\n",
      "[TensorShape([None, 2608, 32])]\n",
      "[TensorShape([None, 2608, 32]), TensorShape([None, 2608, 32])]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_1 (InputLayer)      [(None, 26086, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding1d (ZeroPadding1D)  (None, 26086, 1)     0           input_layer_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected1d (LocallyCon (None, 2608, 32)     834560      zero_padding1d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2608, 32)     1056        locally_connected1d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_qkv__block_attention ((2608, 32), (2608,  3200        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2608, 32)     0           multi_head_qkv__block_attention[0\n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 2608, 32)     64          add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2608, 32)     1056        layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 2608, 32)     0           dense_1[0][0]                    \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    multiple             0           add_1[0][0]                      \n",
      "                                                                 add_3[0][0]                      \n",
      "                                                                 add_4[0][0]                      \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_qkv__block_attention ((None, 2608, 32), ( 3200        re_lu[0][0]                      \n",
      "                                                                 multi_head_qkv__block_attention[0\n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 2608, 32)     0           multi_head_qkv__block_attention_1\n",
      "                                                                 re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 2608, 32)     64          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2608, 32)     1056        layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 2608, 32)     0           dense_2[0][0]                    \n",
      "                                                                 layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 83456)        0           re_lu[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 83456)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          21364992    dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          65792       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 256)          0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          65792       re_lu[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            257         re_lu[3][0]                      \n",
      "==================================================================================================\n",
      "Total params: 22,341,089\n",
      "Trainable params: 22,341,089\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "(2608, 1, 32)\n"
     ]
    }
   ],
   "source": [
    "Model_path = user_profile+\"OneDrive - The University of Queensland/PhD/HPC_Results/Sugarcane_disease/ML/1Head_RealForm32_32LocalB/\"\n",
    "records = []\n",
    "for trait in [\"smut\",\"pachy\"]:\n",
    "    for val in range(1,6):\n",
    "        filename = Model_path + trait + \"_MultiHeadAttentionLNN_\"+str(val)\n",
    "        record = export_LD_attention_score_by_trait(filename,trait,val)\n",
    "        records.append(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordss = []\n",
    "for i in records:\n",
    "    for j in i:\n",
    "        recordss.append(j)\n",
    "records_df = pd.DataFrame(recordss,columns=[\"Trait\",\"Val\",\"Channel\"]+list(range(1,2609)))\n",
    "output_path = Model_path + \"Attention_block_Normscore_bychannel.csv\"\n",
    "records_df.to_csv(output_path,sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records.insert(0,\"Val\", #columns.values[0:2] = [\"Trait\",\"Val\"]\n",
    "output_path = Model_path + \"Attention_score.csv\"\n",
    "records.to_csv(output_path,sep=\"\\t\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trait</th>\n",
       "      <th>Val</th>\n",
       "      <th>Channel</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>2599</th>\n",
       "      <th>2600</th>\n",
       "      <th>2601</th>\n",
       "      <th>2602</th>\n",
       "      <th>2603</th>\n",
       "      <th>2604</th>\n",
       "      <th>2605</th>\n",
       "      <th>2606</th>\n",
       "      <th>2607</th>\n",
       "      <th>2608</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smut</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.053384</td>\n",
       "      <td>-0.956152</td>\n",
       "      <td>2.189313</td>\n",
       "      <td>-0.647232</td>\n",
       "      <td>0.594774</td>\n",
       "      <td>-1.005392</td>\n",
       "      <td>-0.623748</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.573900</td>\n",
       "      <td>-0.649464</td>\n",
       "      <td>2.171458</td>\n",
       "      <td>-0.063063</td>\n",
       "      <td>-0.376861</td>\n",
       "      <td>-0.318065</td>\n",
       "      <td>1.236210</td>\n",
       "      <td>1.875976</td>\n",
       "      <td>-0.218107</td>\n",
       "      <td>0.179610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smut</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.263064</td>\n",
       "      <td>-0.415714</td>\n",
       "      <td>-1.451103</td>\n",
       "      <td>-0.648146</td>\n",
       "      <td>-0.479885</td>\n",
       "      <td>0.312893</td>\n",
       "      <td>1.548072</td>\n",
       "      <td>...</td>\n",
       "      <td>1.669782</td>\n",
       "      <td>-0.979295</td>\n",
       "      <td>-0.191333</td>\n",
       "      <td>-0.702827</td>\n",
       "      <td>2.470894</td>\n",
       "      <td>-0.337153</td>\n",
       "      <td>-0.664402</td>\n",
       "      <td>-0.361315</td>\n",
       "      <td>-0.489121</td>\n",
       "      <td>-0.256168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>smut</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.012067</td>\n",
       "      <td>-0.915943</td>\n",
       "      <td>1.618387</td>\n",
       "      <td>-0.610754</td>\n",
       "      <td>0.235670</td>\n",
       "      <td>-0.964619</td>\n",
       "      <td>-0.587350</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.602530</td>\n",
       "      <td>-0.678476</td>\n",
       "      <td>1.977512</td>\n",
       "      <td>-0.087632</td>\n",
       "      <td>0.049790</td>\n",
       "      <td>-0.608356</td>\n",
       "      <td>1.182622</td>\n",
       "      <td>1.494565</td>\n",
       "      <td>-0.244265</td>\n",
       "      <td>0.716075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>smut</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.346142</td>\n",
       "      <td>-0.443261</td>\n",
       "      <td>-1.486278</td>\n",
       "      <td>-0.374852</td>\n",
       "      <td>-0.507371</td>\n",
       "      <td>0.219723</td>\n",
       "      <td>1.382270</td>\n",
       "      <td>...</td>\n",
       "      <td>1.734046</td>\n",
       "      <td>-0.834634</td>\n",
       "      <td>-0.167471</td>\n",
       "      <td>-0.726386</td>\n",
       "      <td>2.582892</td>\n",
       "      <td>-0.216003</td>\n",
       "      <td>-0.687492</td>\n",
       "      <td>-0.381337</td>\n",
       "      <td>-0.510485</td>\n",
       "      <td>-0.354114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows  2611 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Trait  Val  Channel         1         2         3         4         5  \\\n",
       "0  smut    1        1 -1.053384 -0.956152  2.189313 -0.647232  0.594774   \n",
       "1  smut    1        2 -0.263064 -0.415714 -1.451103 -0.648146 -0.479885   \n",
       "2  smut    1        3 -1.012067 -0.915943  1.618387 -0.610754  0.235670   \n",
       "3  smut    1        4 -0.346142 -0.443261 -1.486278 -0.374852 -0.507371   \n",
       "\n",
       "          6         7  ...      2599      2600      2601      2602      2603  \\\n",
       "0 -1.005392 -0.623748  ... -0.573900 -0.649464  2.171458 -0.063063 -0.376861   \n",
       "1  0.312893  1.548072  ...  1.669782 -0.979295 -0.191333 -0.702827  2.470894   \n",
       "2 -0.964619 -0.587350  ... -0.602530 -0.678476  1.977512 -0.087632  0.049790   \n",
       "3  0.219723  1.382270  ...  1.734046 -0.834634 -0.167471 -0.726386  2.582892   \n",
       "\n",
       "       2604      2605      2606      2607      2608  \n",
       "0 -0.318065  1.236210  1.875976 -0.218107  0.179610  \n",
       "1 -0.337153 -0.664402 -0.361315 -0.489121 -0.256168  \n",
       "2 -0.608356  1.182622  1.494565 -0.244265  0.716075  \n",
       "3 -0.216003 -0.687492 -0.381337 -0.510485 -0.354114  \n",
       "\n",
       "[4 rows x 2611 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2608, 1, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2598</th>\n",
       "      <th>2599</th>\n",
       "      <th>2600</th>\n",
       "      <th>2601</th>\n",
       "      <th>2602</th>\n",
       "      <th>2603</th>\n",
       "      <th>2604</th>\n",
       "      <th>2605</th>\n",
       "      <th>2606</th>\n",
       "      <th>2607</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.025982</td>\n",
       "      <td>-0.039928</td>\n",
       "      <td>-0.040407</td>\n",
       "      <td>0.034194</td>\n",
       "      <td>-0.028745</td>\n",
       "      <td>0.087532</td>\n",
       "      <td>-0.052552</td>\n",
       "      <td>0.028997</td>\n",
       "      <td>-0.003427</td>\n",
       "      <td>0.022198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052552</td>\n",
       "      <td>0.028997</td>\n",
       "      <td>-0.003427</td>\n",
       "      <td>0.022198</td>\n",
       "      <td>-0.040022</td>\n",
       "      <td>0.029404</td>\n",
       "      <td>0.095634</td>\n",
       "      <td>0.049117</td>\n",
       "      <td>-0.036483</td>\n",
       "      <td>0.100009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.042523</td>\n",
       "      <td>0.015336</td>\n",
       "      <td>0.029727</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.016146</td>\n",
       "      <td>0.024049</td>\n",
       "      <td>0.012860</td>\n",
       "      <td>0.035353</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024049</td>\n",
       "      <td>0.012860</td>\n",
       "      <td>0.035353</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>0.013306</td>\n",
       "      <td>0.053255</td>\n",
       "      <td>0.023715</td>\n",
       "      <td>0.039082</td>\n",
       "      <td>0.016013</td>\n",
       "      <td>0.041146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.023426</td>\n",
       "      <td>-0.081781</td>\n",
       "      <td>-0.055501</td>\n",
       "      <td>0.004935</td>\n",
       "      <td>-0.030349</td>\n",
       "      <td>0.071640</td>\n",
       "      <td>-0.076222</td>\n",
       "      <td>0.016339</td>\n",
       "      <td>-0.038224</td>\n",
       "      <td>0.019152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076222</td>\n",
       "      <td>0.016339</td>\n",
       "      <td>-0.038224</td>\n",
       "      <td>0.019152</td>\n",
       "      <td>-0.053118</td>\n",
       "      <td>-0.023012</td>\n",
       "      <td>0.072292</td>\n",
       "      <td>0.010651</td>\n",
       "      <td>-0.052244</td>\n",
       "      <td>0.059512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.023426</td>\n",
       "      <td>-0.081781</td>\n",
       "      <td>-0.055501</td>\n",
       "      <td>0.004935</td>\n",
       "      <td>-0.030349</td>\n",
       "      <td>0.071640</td>\n",
       "      <td>-0.076222</td>\n",
       "      <td>0.016339</td>\n",
       "      <td>-0.038224</td>\n",
       "      <td>0.019152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076222</td>\n",
       "      <td>0.016339</td>\n",
       "      <td>-0.038224</td>\n",
       "      <td>0.019152</td>\n",
       "      <td>-0.053118</td>\n",
       "      <td>-0.023012</td>\n",
       "      <td>0.072292</td>\n",
       "      <td>0.010651</td>\n",
       "      <td>-0.052244</td>\n",
       "      <td>0.059512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.025982</td>\n",
       "      <td>-0.039928</td>\n",
       "      <td>-0.040407</td>\n",
       "      <td>0.034194</td>\n",
       "      <td>-0.028745</td>\n",
       "      <td>0.087532</td>\n",
       "      <td>-0.052552</td>\n",
       "      <td>0.028997</td>\n",
       "      <td>-0.003427</td>\n",
       "      <td>0.022198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052552</td>\n",
       "      <td>0.028997</td>\n",
       "      <td>-0.003427</td>\n",
       "      <td>0.022198</td>\n",
       "      <td>-0.040022</td>\n",
       "      <td>0.029404</td>\n",
       "      <td>0.095634</td>\n",
       "      <td>0.049117</td>\n",
       "      <td>-0.036483</td>\n",
       "      <td>0.100009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.028538</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>-0.025312</td>\n",
       "      <td>0.063452</td>\n",
       "      <td>-0.027142</td>\n",
       "      <td>0.103424</td>\n",
       "      <td>-0.028882</td>\n",
       "      <td>0.041654</td>\n",
       "      <td>0.031370</td>\n",
       "      <td>0.025243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028882</td>\n",
       "      <td>0.041654</td>\n",
       "      <td>0.031370</td>\n",
       "      <td>0.025243</td>\n",
       "      <td>-0.026926</td>\n",
       "      <td>0.081821</td>\n",
       "      <td>0.118975</td>\n",
       "      <td>0.087583</td>\n",
       "      <td>-0.020723</td>\n",
       "      <td>0.140507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.028538</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>-0.025312</td>\n",
       "      <td>0.063452</td>\n",
       "      <td>-0.027142</td>\n",
       "      <td>0.103424</td>\n",
       "      <td>-0.028882</td>\n",
       "      <td>0.041654</td>\n",
       "      <td>0.031370</td>\n",
       "      <td>0.025243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028882</td>\n",
       "      <td>0.041654</td>\n",
       "      <td>0.031370</td>\n",
       "      <td>0.025243</td>\n",
       "      <td>-0.026926</td>\n",
       "      <td>0.081821</td>\n",
       "      <td>0.118975</td>\n",
       "      <td>0.087583</td>\n",
       "      <td>-0.020723</td>\n",
       "      <td>0.140507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  2608 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5     \\\n",
       "count  32.000000  32.000000  32.000000  32.000000  32.000000  32.000000   \n",
       "mean    0.025982  -0.039928  -0.040407   0.034194  -0.028745   0.087532   \n",
       "std     0.002597   0.042523   0.015336   0.029727   0.001629   0.016146   \n",
       "min     0.023426  -0.081781  -0.055501   0.004935  -0.030349   0.071640   \n",
       "25%     0.023426  -0.081781  -0.055501   0.004935  -0.030349   0.071640   \n",
       "50%     0.025982  -0.039928  -0.040407   0.034194  -0.028745   0.087532   \n",
       "75%     0.028538   0.001925  -0.025312   0.063452  -0.027142   0.103424   \n",
       "max     0.028538   0.001925  -0.025312   0.063452  -0.027142   0.103424   \n",
       "\n",
       "            6          7          8          9     ...       2598       2599  \\\n",
       "count  32.000000  32.000000  32.000000  32.000000  ...  32.000000  32.000000   \n",
       "mean   -0.052552   0.028997  -0.003427   0.022198  ...  -0.052552   0.028997   \n",
       "std     0.024049   0.012860   0.035353   0.003094  ...   0.024049   0.012860   \n",
       "min    -0.076222   0.016339  -0.038224   0.019152  ...  -0.076222   0.016339   \n",
       "25%    -0.076222   0.016339  -0.038224   0.019152  ...  -0.076222   0.016339   \n",
       "50%    -0.052552   0.028997  -0.003427   0.022198  ...  -0.052552   0.028997   \n",
       "75%    -0.028882   0.041654   0.031370   0.025243  ...  -0.028882   0.041654   \n",
       "max    -0.028882   0.041654   0.031370   0.025243  ...  -0.028882   0.041654   \n",
       "\n",
       "            2600       2601       2602       2603       2604       2605  \\\n",
       "count  32.000000  32.000000  32.000000  32.000000  32.000000  32.000000   \n",
       "mean   -0.003427   0.022198  -0.040022   0.029404   0.095634   0.049117   \n",
       "std     0.035353   0.003094   0.013306   0.053255   0.023715   0.039082   \n",
       "min    -0.038224   0.019152  -0.053118  -0.023012   0.072292   0.010651   \n",
       "25%    -0.038224   0.019152  -0.053118  -0.023012   0.072292   0.010651   \n",
       "50%    -0.003427   0.022198  -0.040022   0.029404   0.095634   0.049117   \n",
       "75%     0.031370   0.025243  -0.026926   0.081821   0.118975   0.087583   \n",
       "max     0.031370   0.025243  -0.026926   0.081821   0.118975   0.087583   \n",
       "\n",
       "            2606       2607  \n",
       "count  32.000000  32.000000  \n",
       "mean   -0.036483   0.100009  \n",
       "std     0.016013   0.041146  \n",
       "min    -0.052244   0.059512  \n",
       "25%    -0.052244   0.059512  \n",
       "50%    -0.036483   0.100009  \n",
       "75%    -0.020723   0.140507  \n",
       "max    -0.020723   0.140507  \n",
       "\n",
       "[8 rows x 2608 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_layer_model = tf.keras.Model(inputs=model.input,\n",
    "                                         outputs=model.get_layer('multi_head_qkv__block_attention').output)\n",
    "intermediate_output = intermediate_layer_model.predict(data)\n",
    "attention = intermediate_output[0]\n",
    "attention = K.expand_dims(attention,axis=1)\n",
    "print(attention.shape)\n",
    "pd.DataFrame(np.array(tf.reshape(attention,(32,2608)))).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (PHD_Notebook)",
   "language": "python",
   "name": "pycharm-3bcd6117"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
