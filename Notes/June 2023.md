1. Current work:

   1. HPC environment transferred into Tensorflow 2.9; DONE
   2. MultiLevel Attention development DONE
      1. Main feature 1: added a matrix of attention weights (SNPxSNP int) after softmax(QK^T) to measure weather the dependency is neccessury
      2. Use 1x1 conv1D and Global average pooling instead of flatten and fully connect layer to generate outputs
      3. The prediction section was changed into a double-portal section:
         1.  A linear one-layer MLP section to predict linear component 
         2.  A non-linear MLP section to predict non-linear component 
   3. make 1000 SNP by PIP DONE
   4. Add dominance attention to Multi-Level
   5. Slides for zoom meeting
   6. 

![image-20230612100409289](C:\Users\70651\AppData\Roaming\Typora\typora-user-images\image-20230612100409289.png)

Circle like position encoding for SNPs and further data:

1st channel: SNP signal

2,3..n channel: circular, spherical, even higher dimensional encoding - make sure the starting position for each SNP is equal to the "trait"

Question: how to merge (convert) SNPs with positions together without loss equal? Conv+LCL?

29k -- LCL to 2608 SNP then positional encoding (2608) ---> (signal, positional_x, postional_y) then embedding to N channel -- encoding

LCL at first;

positional encoding;

embedding

attention;

split signals to positional channels equally by encoder 



The sugarcane yields dataset

https://doi.org/10.6084/m9.figshare.21709481.v1 (Post process dataset)

https://doi.org/10.6084/m9.figshare.23540574.v1 (Industry dataset)

including 2912 clones and 3 yields traits.



```bash
composer="D:/PhD_Notebook/Code/ML_composer/"
geno="H:/ML_archive/Data/sugarcane/sugarcane_yield"
pheno="H:/ML_archive/Data/sugarcane/sugarcane_yield.phen"
index="H:/ML_archive/Data/sugarcane/sugarcane_yield.index"
#anno="H:/ML_archive/Data/sugarcane/sugarcane_yield.anno"
target="H:/ML_archive/test_model_yield" 
loss="mse"

##If on HPC
geno="/scratch/qaafi/uqcche32/sugarcane_yield/data/sugarcane_yield"
pheno="/scratch/qaafi/uqcche32/sugarcane_yield/data/sugarcane_yield.phen"
index="/scratch/qaafi/uqcche32/sugarcane_yield/data/sugarcane_yield.index"
#anno="/scratch/qaafi/uqcche32/sugarcane_yield/data/disease_subset.anno"
target="H:/ML_archive/test_model" 

target="H:/ML_archive/test_model_yield_conv"
trait="TCH"
python $composer/GS_composer.py --ped $geno --pheno $pheno --mpheno 1 --index $index --vindex 2 --trait $trait --width 256 --depth 1 --model "MultiLevel Attention" -o $target --quiet 1 --plot --epoch 10 --round 5 --locallyConnect 16 --embedding 16 --batch 16 --num-heads 1 --locallyBlock 10 --lr 0.001 --loss $loss

##########Perform 1 channel attention (modified) FOR DISEASE trait.

composer="D:/PhD_Notebook/Code/ML_composer/"
pheno="H:/ML_archive/Data/sugarcane_disease/sugarcane_disease.phen"
index="H:/ML_archive/Data/sugarcane_disease/sugarcane_disease.index"
trait="smut"
#trait="pachy"
loss="cor_mse"
LB=1
LC=16
AB=2
echo $trait
for idx in {1..5}
do
geno="H:/ML_archive/Data/sugarcane_disease/sugarcane_disease_1000_v${idx}_${trait}"
target="H:/ML_archive/PIP_attention/v${idx}_1LB_${LC}LC/"
python $composer/GS_composer.py --ped $geno --pheno $pheno --mpheno 1 --index $index --trait $trait --width 256 --depth 1 --model "MultiLevel Attention" -o $target --quiet 1 --plot --epoch 30 --round 1 --locallyConnect $LC --embedding $LC --AttentionBlock $AB --batch 256 --num-heads 1 --locallyBlock $LB --vindex $idx --lr 0.001 --loss $loss
done
```



#########Test normal attention block whole dataset#######

```bash
composer="D:/PhD_Notebook/Code/ML_composer/"

geno="H:/ML_archive/Data/sugarcane_disease/sugarcane_disease"
pheno="H:/ML_archive/Data/sugarcane_disease/sugarcane_disease.phen"
index="H:/ML_archive/Data/sugarcane_disease/sugarcane_disease.index"
#anno="H:/ML_archive/Data/sugarcane_disease/sugarcane_disease.anno"
trait="smut"
#trait="pachy"
loss="mse"
LB=10
LC=16
AB=2
target="H:/ML_archive/v${idx}_${LB}LB_${LC}LC_${AB}AttentionBlock_noEpi/" 
python $composer/GS_composer.py --ped $geno --pheno $pheno --mpheno 1 --index $index --trait $trait --width 256 --depth 1 --model "MultiLevel Attention" -o $target --quiet 1 --plot --epoch 30 --round 1 --locallyConnect $LC --embedding $LC --AttentionBlock $AB --batch 16 --num-heads 1 --locallyBlock $LB --lr 0.001 --loss $loss
```

