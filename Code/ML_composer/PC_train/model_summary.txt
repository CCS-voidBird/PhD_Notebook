Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_layer_1 (InputLayer)      [(None, 26086, 1)]   0                                            
__________________________________________________________________________________________________
zero_padding1d (ZeroPadding1D)  (None, 26086, 1)     0           input_layer_1[0][0]              
__________________________________________________________________________________________________
locally_connected1d (LocallyCon (None, 2608, 1)      26080       zero_padding1d[0][0]             
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 2608, 8)      8           locally_connected1d[0][0]        
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 2608, 8)      32          conv1d[0][0]                     
__________________________________________________________________________________________________
multi_head__seq__block_attentio ((None, 2608, 8, 260 20928       batch_normalization[0][0]        
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 2608, 8, 2608 10432       multi_head__seq__block_attention[
__________________________________________________________________________________________________
dropout (Dropout)               (None, 2608, 8, 2608 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
multi_head_conv__block_attentio (None, 8, 8, 2608)   20928       dropout[0][0]                    
                                                                 multi_head__seq__block_attention[
__________________________________________________________________________________________________
global_average_pooling2d (Globa (None, 2608)         0           multi_head_conv__block_attention[
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 2608)         0           global_average_pooling2d[0][0]   
__________________________________________________________________________________________________
dense (Dense)                   (None, 1)            2609        dropout_1[0][0]                  
==================================================================================================
Total params: 81,017
Trainable params: 75,785
Non-trainable params: 5,232
__________________________________________________________________________________________________
