{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0caae4f",
   "metadata": {},
   "source": [
    "TEST ML_composer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a3f995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\PhD_Notebook\\Code\\ML_composer\n",
      "This is not a GPU env.\n",
      "WARNING:tensorflow:From C:\\Users\\uqcche32\\AppData\\Local\\Temp\\ipykernel_18608\\813091426.py:37: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.run_functions_eagerly` instead of the experimental version.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir(\"F:/project/sugarcane_disease/\")\n",
    "#os.chdir(\"O:/project/sugarcane_disease/\")\n",
    "os.getcwd()\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "try:\n",
    "    import keras\n",
    "    from keras.models import Sequential\n",
    "    from tensorflow.keras import layers\n",
    "    from keras.layers import MaxPooling1D, Flatten, Dense, Conv1D,MaxPooling2D, Conv2D\n",
    "    from keras.layers import Dropout\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    import tensorflow as tf\n",
    "    import keras.metrics\n",
    "except:\n",
    "    try:\n",
    "        from tensorflow import keras\n",
    "        from tensorflow.keras import layers\n",
    "        from tensorflow.keras.models import Sequential\n",
    "        from tensorflow.keras.utils import to_categorical\n",
    "        from tensorflow.keras.layers import MaxPooling1D, Flatten, Dense, Conv1D,MaxPooling2D, Conv2D, Dropout\n",
    "        import tensorflow as tf\n",
    "        from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "        print(\"Use tensorflow backend keras module\")\n",
    "    except:\n",
    "        print(\"This is not a GPU env.\")\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import configparser\n",
    "from Functions import *\n",
    "from tensorflow.keras.layers import Layer\n",
    "from CustomLayers import *\n",
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "# Define the residual block as a new layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "671d1f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is not a GPU env.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from GS_composer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68c7d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ClassModel import *\n",
    "from CustomLayers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47742d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ffdb784",
   "metadata": {},
   "outputs": [],
   "source": [
    "class p_args:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.ped = \"sugarcane_disease\"\n",
    "        self.pheno = \"sugarcane_disease.pheno\"\n",
    "        self.mpheno = 1\n",
    "        self.index = \"sugarcane_disease.index\"\n",
    "        self.model = \"Attention CNN\"\n",
    "        self.load = None\n",
    "        self.trait = \"trait\"\n",
    "        self.output = \"./results\"\n",
    "        self.round = 10\n",
    "        self.plot = True\n",
    "        self.epoch = 50\n",
    "        self.rank =True\n",
    "        self.lr = 0.0001\n",
    "        self.batch = 2\n",
    "        self.mean = False\n",
    "        self.depth = 0\n",
    "        self.quiet = 1\n",
    "        \n",
    "args = p_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eee6c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "238677a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionCNN(NN):\n",
    "\n",
    "    def __init__(self,args):\n",
    "        super(AttentionCNN,self).__init__(args)\n",
    "        self.name = \"Attention CNN\"\n",
    "        self.rank = True  ##rank block value to 0 (zero),1 (low),2 (high).\n",
    "        self.args = args\n",
    "\n",
    "    def model_name(self):\n",
    "        #get class name\n",
    "        return self.__class__.__name__\n",
    "\n",
    "    def data_transform(self,geno,pheno,anno=None,pheno_standard = False):\n",
    "\n",
    "        print(\"USE Attention CNN MODEL as training method\")\n",
    "        geno = decoding(geno)\n",
    "        geno = np.expand_dims(geno, axis=2)\n",
    "        #pos = np.arrays(range(geno.shape[1]))\n",
    "        #pos = np.expand_dims(pos, axis=0)\n",
    "        print(\"The transformed SNP shape:\", geno.shape)\n",
    "\n",
    "        if pheno_standard is True:\n",
    "            pheno = stats.zscore(pheno)\n",
    "        return geno,pheno\n",
    "\n",
    "    def model(self, input_shape,args, optimizer=\"rmsprop\", lr=0.00001):\n",
    "        # init Q,K,V\n",
    "        depth = args.depth\n",
    "        input1 = layers.Input(shape=input_shape,name=\"input_layer_1\")\n",
    "\n",
    "        X = layers.ZeroPadding1D(padding=(0, input_shape[1]//10))(input1)\n",
    "        \n",
    "\n",
    "        V = layers.LocallyConnected1D(1,10,strides=10, activation=\"relu\",padding=\"valid\",use_bias=False)(X)\n",
    "        V = layers.Conv1D(8,kernel_size=1,strides=1,activation='relu')(V)\n",
    "        V = layers.LayerNormalization()(V)\n",
    "\n",
    "        M = MultiHead_QK_BlockAttention()(V)\n",
    "\n",
    "        while depth > 0:\n",
    "            M = residual_fl_block(input=M, width=self.args.width, downsample=(depth % 2 == 0 & self.args.residual))\n",
    "            depth -= 1\n",
    "        QV_output = layers.Dense(1, activation=\"linear\")(M)\n",
    "\n",
    "        try:\n",
    "            adm = keras.optimizers.Adam(learning_rate=lr)\n",
    "            rms = keras.optimizers.RMSprop(learning_rate=lr)\n",
    "            sgd = keras.optimizers.SGD(learning_rate=lr)\n",
    "        except:\n",
    "            adm = keras.optimizers.Adam(lr=lr)\n",
    "            rms = keras.optimizers.RMSprop(lr=lr)\n",
    "            sgd = keras.optimizers.SGD(lr=lr)\n",
    "\n",
    "        optimizers = {\"rmsprop\": rms,\n",
    "                      \"Adam\": adm,\n",
    "                      \"SGD\": sgd}\n",
    "\n",
    "        model = keras.Model(inputs=input1, outputs=QV_output)\n",
    "        model.compile(optimizer=optimizers[optimizer], loss=\"mean_squared_error\")\n",
    "\n",
    "        #QK = layers.Dot(axes=[2, 2])([Q_encoding, K_encoding])\n",
    "        #QK = layers.Softmax(axis=-1)(QK)\n",
    "        #QKV = layers.Dot(axes=[2, 1])([QK, V_encoding])\n",
    "        #QKV = layers.Flatten()(QKV)\n",
    "        #QKV = layers.Dense(1, activation=\"linear\")(QKV)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0353d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.output[0] == \"/\":\n",
    "    locat = '/' + args.output.strip('/') + '/'\n",
    "else:\n",
    "    locat = args.output.strip('/') + '/'\n",
    "if not os.path.exists(locat):\n",
    "    os.mkdir(locat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48126528",
   "metadata": {},
   "outputs": [],
   "source": [
    "composer = ML_composer()\n",
    "composer._model\n",
    "composer.silence_mode = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e24f9015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#composer.get_data(config,args)\n",
    "composer.args = args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0f3e51a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "composer.prepare_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "33e285a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ref = composer.prepare_cross_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f427e486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validate: ([2, 3, 4, 5], [1])\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross-validate: {}\".format(index_ref[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c7ee35e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx,valid_idx = index_ref[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1d64bf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall population: 4702\n",
      "759 individuals need to be removed due to the miss phenotype\n",
      "Filtered population: 3943\n",
      "Mean of train phenotype: 4.715129635707253\n",
      "Use raw phenotype as the target\n",
      "16    1\n",
      "39    3\n",
      "44    3\n",
      "47    2\n",
      "92    3\n",
      "Name: 2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "composer.prepare_training(train_idx,valid_idx)\n",
    "#composer.batchSize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6a9ec790",
   "metadata": {},
   "outputs": [],
   "source": [
    "#composer._raw_data[\"GENO\"].iloc[:,6:].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "54a38a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE Attention CNN MODEL as training method\n",
      "Convert data to np.array float32\n",
      "The transformed SNP shape: (3047, 26086, 1)\n",
      "USE Attention CNN MODEL as training method\n",
      "Convert data to np.array float32\n",
      "The transformed SNP shape: (896, 26086, 1)\n",
      "Train status:\n",
      "Epochs:  50\n",
      "Repeat(Round):  10\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_1 (InputLayer)   [(None, 26086, 1)]        0         \n",
      "_________________________________________________________________\n",
      "zero_padding1d_1 (ZeroPaddin (None, 26086, 1)          0         \n",
      "_________________________________________________________________\n",
      "locally_connected1d_1 (Local (None, 2608, 1)           26080     \n",
      "_________________________________________________________________\n",
      "block_attention_1 (BlockAtte (None, 1, 2608)           13605936  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1, 1)              2609      \n",
      "=================================================================\n",
      "Total params: 13,634,625\n",
      "Trainable params: 13,632,017\n",
      "Non-trainable params: 2,608\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 387/1524 [======>.......................] - ETA: 8:48 - loss: 1.0406"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcomposer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalid_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\PhD_Notebook\\Code\\ML_composer\\GS_composer.py:269\u001b[0m, in \u001b[0;36mML_composer.compose\u001b[1;34m(self, train_index, valid_index, val)\u001b[0m\n\u001b[0;32m    267\u001b[0m val_record \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mround\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mround:\n\u001b[1;32m--> 269\u001b[0m     history, test_accuracy, runtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_val\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m     valid_accuracy, mse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_validation()\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m valid_accuracy \u001b[38;5;241m>\u001b[39m val_record:\n",
      "File \u001b[1;32mF:\\PhD_Notebook\\Code\\ML_composer\\GS_composer.py:230\u001b[0m, in \u001b[0;36mML_composer.train\u001b[1;34m(self, features_train, features_test, target_train, target_test, round)\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is a sklean-Random-forest model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m startTime \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m--> 230\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTRAINED_MODEL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfeatures_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatchSize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# let's just print the final loss\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m - train loss     : \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1183\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1177\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1178\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1179\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1180\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1181\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1182\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1183\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1184\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1185\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:855\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_function\u001b[39m(iterator):\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;124;03m\"\"\"Runs a training execution with one step.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 855\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstep_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m    842\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[0;32m    844\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m--> 845\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    846\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m    847\u001b[0m     outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    848\u001b[0m write_scalar_summaries(outputs, step\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39m_train_counter)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m   1281\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[0;32m   1284\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1285\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2831\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   2832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m-> 2833\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3606\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3607\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m-> 3608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:597\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    596\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:838\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[1;32m--> 838\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    839\u001b[0m   \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m    840\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[38;5;66;03m# Run forward pass.\u001b[39;00m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m backprop\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m--> 795\u001b[0m   y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_loss(\n\u001b[0;32m    797\u001b[0m       y, y_pred, sample_weight, regularization_losses\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses)\n\u001b[0;32m    798\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1030\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1026\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1029\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1030\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1033\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:420\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;129m@doc_controls\u001b[39m\u001b[38;5;241m.\u001b[39mdo_not_doc_inheritable\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    403\u001b[0m   \u001b[38;5;124;03m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \n\u001b[0;32m    405\u001b[0m \u001b[38;5;124;03m  In this case `call` just reapplies\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;124;03m      a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 420\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_internal_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:556\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    553\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[0;32m    555\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[1;32m--> 556\u001b[0m outputs \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mlayer(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    558\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_id, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39mflat_output_ids, nest\u001b[38;5;241m.\u001b[39mflatten(outputs)):\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1030\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1026\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1029\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1030\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1033\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\local.py:264\u001b[0m, in \u001b[0;36mLocallyConnected1D.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[0;32m    263\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimplementation \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 264\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_conv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m   \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimplementation \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    269\u001b[0m     output \u001b[38;5;241m=\u001b[39m local_conv_matmul(inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_mask,\n\u001b[0;32m    270\u001b[0m                                \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_output_shape(inputs\u001b[38;5;241m.\u001b[39mshape))\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:5871\u001b[0m, in \u001b[0;36mlocal_conv\u001b[1;34m(inputs, kernel, kernel_size, strides, output_shape, data_format)\u001b[0m\n\u001b[0;32m   5868\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannels_last\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   5869\u001b[0m     slices\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m-> 5871\u001b[0m   xs\u001b[38;5;241m.\u001b[39mappend(reshape(\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mslices\u001b[49m\u001b[43m]\u001b[49m, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, feature_dim)))\n\u001b[0;32m   5873\u001b[0m x_aggregate \u001b[38;5;241m=\u001b[39m concatenate(xs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   5874\u001b[0m output \u001b[38;5;241m=\u001b[39m batch_dot(x_aggregate, kernel)\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1040\u001b[0m, in \u001b[0;36m_slice_helper\u001b[1;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[0;32m   1038\u001b[0m   var_empty \u001b[38;5;241m=\u001b[39m constant([], dtype\u001b[38;5;241m=\u001b[39mdtypes\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m   1039\u001b[0m   packed_begin \u001b[38;5;241m=\u001b[39m packed_end \u001b[38;5;241m=\u001b[39m packed_strides \u001b[38;5;241m=\u001b[39m var_empty\n\u001b[1;32m-> 1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstrided_slice\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1041\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked_begin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked_end\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked_strides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbegin_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1213\u001b[0m, in \u001b[0;36mstrided_slice\u001b[1;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strides \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1211\u001b[0m   strides \u001b[38;5;241m=\u001b[39m ones_like(begin)\n\u001b[1;32m-> 1213\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrided_slice\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbegin_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1225\u001b[0m parent_name \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mF:\\miniconda\\envs\\AIGS_py39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:10498\u001b[0m, in \u001b[0;36mstrided_slice\u001b[1;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[0;32m  10496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m  10497\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m> 10498\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  10499\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mStridedSlice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbegin_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10500\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mellipsis_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10501\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnew_axis_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshrink_axis_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  10502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m  10503\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "composer.compose(train_idx,valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "46441d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf \n",
    "\n",
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a52cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.5//1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9106dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e2bf9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d970bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ref = composer.prepare_cross_validate()\n",
    "i = 1\n",
    "for train_idx,valid_idx in index_ref:\n",
    "    print(\"Cross-validate: {}\".format(i))\n",
    "    composer.prepare_training(train_idx,valid_idx)\n",
    "    composer.compose(train_idx,valid_idx)\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
